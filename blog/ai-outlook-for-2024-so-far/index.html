<!DOCTYPE html>
<html>
    <head>
        <meta name="viewport" content="width=device-width">
        <meta http-equiv="content-type" content="text/html; charset=UTF-8">
        
        <link rel="stylesheet" href="../+assets/blog.css">
        <link rel="stylesheet" href="/assets/font-awesome-5-15-4/css/all.min.css">
        <script defer src="/assets/font-awesome-5-15-4/attribution.js"></script>
        <script defer src="../+assets/highlight.min.js"></script>
        <script defer src="/dokki/distributable/dokki.js"></script>
        <script type="module" src="../+assets/blog-post-widgets.js"></script>
        <script type="module" src="../+assets/post-date.js"></script>
    </head>
    <body>
        <ths-feedback></ths-feedback>
        
    
            <template id="dokki">
                <dokki-document>
                    <dokki-header>
                        <template #caption>
                            
                AI outlook for 2024 so far
            
                        </template>
                        <template #widgets>
                <blog-post-widgets></blog-post-widgets>
            </template>
                    </dokki-header>
                    <dokki-topics>
                        
<post-date date="18 July 2024"></post-date>
<dokki-topic title="AI outlook for 2024 so far">
<dokki-image src="./sade.webp" width="512" height="384"     headerless="true"  no-border-rounding="true"  thumbnail-src="data:image/png;base64,UklGRu4AAABXRUJQVlA4IOIAAAAwBQCdASoUAA8APm0skUWkIqGYBABABsS2AE6ZQjgRYFWzdKORGIdaeDyAMbv0yx5GkAD2uPpGNYI85bJ3MbV+sQ6T87x01bv8d7DqOyvQZaL3mz4RIF4daX3a5V95HL0JocWiJiVlWl/NGYYtxfroytcYNDedw9nwk5oZ0a8fSCSSwiDsifvnNQBJw8vpDuFsfbIiopswmAldwFBtxTREjC9N33k6f/O4bCZULrm/lvZcLiatm17kxasS9vbB3QiUiJkJmTrme0rs3v48Q7swa0j+Dkyf4QTMo+4Ji9+XUkAA">
                        </dokki-image>
<p>The first half of 2024 is done, and along have come a number of new AI models.</p>
<ul>
<li>Claude 3 Opus introduced, among other things, breakthrough abilities in low-resource languages.</li>
<li>GPT-4o raised the bar in visual cognition and is scheduled to do the same for voice.</li>
<li>Gemini 1.5 Pro caught up as a top performer, after Google's slow start last year.</li>
<li>Open models brought local capabilities to par with mid-range commercial offerings. For example, <a href="/blog/testing-a-medley-of-local-llms-for-coding/">in my coding benchmark</a>, Yi 1.5 and Gemma 2 are competitive with Mistral Large.</li>
</ul>
<p>It's not long ago that Anthropic's CEO predicted 2024 would be an interim year for LLMs, improvements but no major shakes. That's more or less what the first half of the year has delivered.</p>
<p>The lack of agency looks to remain an unsolved problem for the rest of the year, limiting bigger social breakthroughs for AI. The cognition of the human agent has its limits, and in my view current-gen AI is already bottlenecked by them.</p>
<p>But going forward, it seems plausible that the rest of the year will finally produce post-GPT-4 AI. There are now several models that are genuinely competitive with GPT-4 and appear to be carrying momentum. The recent release of Claude 3.5 Sonnet, for example, seems to indicate that the path is open.</p>
</dokki-topic>

                    </dokki-topics>
                </dokki-document>
            </template>
        </body>
</html>
